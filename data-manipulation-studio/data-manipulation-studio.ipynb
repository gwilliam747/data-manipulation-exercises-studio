{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit the data set from our last studio. If you recall, California farmers were looking for advice on growing pumpkins. We will use the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "A **terminal market** is a central site, often in a metropolitan area, that serves as an assembly and trading place for commodities. Terminal markets for agricultural commodities are usually at or near major transportation hubs. [Definition Source](https://en.wikipedia.org/wiki/Terminal_market#:~:text=A%20terminal%20market%20is%20a,or%20near%20major%20transportation%20hubs)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "baltimore = pd.read_csv(\"dataset/baltimore_9-24-2016_9-30-2017.csv\")\n",
    "boston = pd.read_csv(\"dataset/boston_9-24-2016_9-30-2017.csv\")\n",
    "new_york = pd.read_csv(\"dataset/new-york_9-24-2016_9-30-2017.csv\")\n",
    "philadelphia = pd.read_csv(\"dataset/philadelphia_9-24-2016_9-30-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data related to San Francisco. Pull up your notebook from the last lesson and use it as a reference to clean up these new dataframes.\n",
    "\n",
    "**Recommended cleaning steps:**\n",
    "1. Handle missing values in the `Type` column (fill with \"Conventional\" if needed)\n",
    "2. Drop irrelevant columns such as `Grade` (only applies to canned pumpkins)\n",
    "3. Drop columns with high percentages of missing data that aren't needed for analysis\n",
    "4. Check for and address any other data quality issues you notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98abc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 1%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 3%\n",
      "Origin District - 100%\n",
      "Item Size - 16%\n",
      "Color - 80%\n",
      "Environment - 100%\n",
      "Unit of Sale - 84%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "# Clean your data here!\n",
    "for col in baltimore.columns:\n",
    "    pct_missing = np.mean(baltimore[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f28adfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 92%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 81%\n",
      "Item Size - 1%\n",
      "Color - 14%\n",
      "Environment - 100%\n",
      "Unit of Sale - 87%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in boston.columns:\n",
    "    pct_missing = np.mean(boston[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2c368db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 87%\n",
      "Item Size - 7%\n",
      "Color - 81%\n",
      "Environment - 100%\n",
      "Unit of Sale - 78%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in new_york.columns:\n",
    "    pct_missing = np.mean(new_york[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd499bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 79%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 100%\n",
      "Item Size - 21%\n",
      "Color - 100%\n",
      "Environment - 100%\n",
      "Unit of Sale - 81%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in philadelphia.columns:\n",
    "    pct_missing = np.mean(philadelphia[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f298a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore[\"Type\"] = baltimore[\"Type\"].fillna(\"Conventional\")\n",
    "boston[\"Type\"] = boston[\"Type\"].fillna(\"Conventional\")\n",
    "new_york[\"Type\"] = new_york[\"Type\"].fillna(\"Conventional\")\n",
    "philadelphia[\"Type\"] = philadelphia[\"Type\"].fillna(\"Conventional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e535f1",
   "metadata": {},
   "source": [
    "No more missing values in the type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f81db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneeded / high-null columns\n",
    "\n",
    "baltimore_cleaned = baltimore.drop([\"Commodity Name\", \"Grade\", \"Sub Variety\", \"Mostly Low\", \"Mostly High\", \"Origin District\", \"Color\", \"Environment\",\n",
    "                  \"Quality\", \"Condition\", \"Appearance\", \"Storage\", \"Crop\", \"Repack\", \"Unit of Sale\", \"Trans Mode\"], axis= 1)\n",
    "boston_cleaned = boston.drop([\"Commodity Name\", \"Grade\", \"Sub Variety\", \"Mostly Low\", \"Mostly High\", \"Origin District\", \"Color\", \"Environment\",\n",
    "                  \"Quality\", \"Condition\", \"Appearance\", \"Storage\", \"Crop\", \"Repack\", \"Unit of Sale\", \"Trans Mode\"], axis= 1)\n",
    "new_york_cleaned = new_york.drop([\"Commodity Name\", \"Grade\", \"Sub Variety\", \"Mostly Low\", \"Mostly High\", \"Origin District\", \"Color\", \"Environment\",\n",
    "                  \"Quality\", \"Condition\", \"Appearance\", \"Storage\", \"Crop\", \"Repack\", \"Unit of Sale\", \"Trans Mode\"], axis= 1)\n",
    "philadelphia_cleaned = philadelphia.drop([\"Commodity Name\", \"Grade\", \"Sub Variety\", \"Mostly Low\", \"Mostly High\", \"Origin District\", \"Color\", \"Environment\",\n",
    "                  \"Quality\", \"Condition\", \"Appearance\", \"Storage\", \"Crop\", \"Repack\", \"Unit of Sale\", \"Trans Mode\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddde2738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   City Name          Type       Package      Variety        Date  Low Price  \\\n",
      "0  BALTIMORE  Conventional  24 inch bins          NaN  04/29/2017        270   \n",
      "1  BALTIMORE  Conventional  24 inch bins          NaN  05/06/2017        270   \n",
      "2  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE  09/24/2016        160   \n",
      "3  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE  09/24/2016        160   \n",
      "4  BALTIMORE  Conventional  24 inch bins  HOWDEN TYPE  11/05/2016         90   \n",
      "\n",
      "   High Price    Origin Item Size  \n",
      "0         280       NaN       lge  \n",
      "1         280       NaN       lge  \n",
      "2         160  DELAWARE       med  \n",
      "3         160  VIRGINIA       med  \n",
      "4         100  MARYLAND       lge  \n"
     ]
    }
   ],
   "source": [
    "# Converting \"High Price\" from float to int\n",
    "\n",
    "baltimore_cleaned[\"High Price\"] = baltimore_cleaned[\"High Price\"].astype(int)\n",
    "boston_cleaned[\"High Price\"] = boston_cleaned[\"High Price\"].astype(int)\n",
    "new_york_cleaned[\"High Price\"] = new_york_cleaned[\"High Price\"].astype(int)\n",
    "philadelphia_cleaned[\"High Price\"] = philadelphia_cleaned[\"High Price\"].astype(int)\n",
    "\n",
    "print(baltimore_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19573a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'DELAWARE', 'VIRGINIA', 'MARYLAND', 'PENNSYLVANIA', 'MEXICO',\n",
       "       'COSTA RICA', 'FLORIDA', 'OHIO'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Package</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Item Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1 1/9 bushel cartons</td>\n",
       "      <td>PIE TYPE</td>\n",
       "      <td>09/16/2017</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1 1/9 bushel cartons</td>\n",
       "      <td>PIE TYPE</td>\n",
       "      <td>09/23/2017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>DELAWARE</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1 1/9 bushel cartons</td>\n",
       "      <td>PIE TYPE</td>\n",
       "      <td>09/23/2017</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1 1/9 bushel cartons</td>\n",
       "      <td>PIE TYPE</td>\n",
       "      <td>09/23/2017</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1 1/9 bushel cartons</td>\n",
       "      <td>PIE TYPE</td>\n",
       "      <td>09/24/2016</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>DELAWARE</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City Name          Type               Package   Variety        Date  \\\n",
       "0  BALTIMORE  Conventional  1 1/9 bushel cartons  PIE TYPE  09/16/2017   \n",
       "1  BALTIMORE  Conventional  1 1/9 bushel cartons  PIE TYPE  09/23/2017   \n",
       "2  BALTIMORE  Conventional  1 1/9 bushel cartons  PIE TYPE  09/23/2017   \n",
       "3  BALTIMORE  Conventional  1 1/9 bushel cartons  PIE TYPE  09/23/2017   \n",
       "4  BALTIMORE  Conventional  1 1/9 bushel cartons  PIE TYPE  09/24/2016   \n",
       "\n",
       "   Low Price  High Price        Origin Item Size  \n",
       "0         18          18      MARYLAND       med  \n",
       "1         16          16      DELAWARE       med  \n",
       "2         16          16  PENNSYLVANIA       med  \n",
       "3         18          18      MARYLAND       med  \n",
       "4         15          15      DELAWARE       med  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the four dataframes into one!\n",
    "northeast = (baltimore_cleaned.merge(boston_cleaned, how= 'outer').merge(new_york_cleaned, how='outer').merge(philadelphia_cleaned, how='outer'))\n",
    "northeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbcc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City Name - 0%\n",
      "Type - 0%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Origin - 1%\n",
      "Item Size - 7%\n"
     ]
    }
   ],
   "source": [
    "#examining null %\n",
    "for col in northeast.columns:\n",
    "    pct_missing = np.mean(northeast[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of **unit of sale** in the Northeast region?\n",
    "2. For the Northeast region, what is the total count of transactions (rows) for each pumpkin variety that came into terminal markets for the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Low Price  High Price\n",
      "Package                                     \n",
      "1 1/9 bushel cartons   15.875000   16.708333\n",
      "1 1/9 bushel crates    16.058824   16.705882\n",
      "1/2 bushel cartons     16.030928   17.597938\n",
      "24 inch bins          188.005618  202.808989\n",
      "36 inch bins          170.458861  196.550633\n",
      "50 lb sacks            25.111111   25.333333\n",
      "bushel cartons         20.571429   22.857143\n",
      "each                   75.000000   80.000000\n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "\n",
    "# In all 4 of these CSVs the \"Unit of Sale\" column is not useable (~80% null values) data.  However, the \"Package\" column contains\n",
    "# the requested information, so I will use this.\n",
    "\n",
    "mean_low_high_price_per_uos = northeast.groupby(\"Package\")[[\"Low Price\", \"High Price\"]].mean()\n",
    "print(mean_low_high_price_per_uos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety\n",
      "BIG MACK TYPE                55\n",
      "BLUE TYPE                     7\n",
      "CINDERELLA                   39\n",
      "FAIRYTALE                    37\n",
      "HOWDEN TYPE                 224\n",
      "HOWDEN WHITE TYPE             2\n",
      "KNUCKLE HEAD                  9\n",
      "MINIATURE                    97\n",
      "MIXED HEIRLOOM VARIETIES      4\n",
      "PIE TYPE                    198\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the total count of transactions for each variety in the Northeast region.\n",
    "transact_count_variety = northeast.groupby(\"Variety\").size()\n",
    "print(transact_count_variety)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for a different region! Choose either:\n",
    "- **Midwest**: Chicago, Detroit, and St. Louis\n",
    "- **Southeast**: Atlanta, Columbia, and Miami\n",
    "\n",
    "Load, clean, and combine the data for your chosen region, then calculate:\n",
    "1. The mean low and high prices for each type of unit of sale\n",
    "2. The total count of transactions for each pumpkin variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
